{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME05Qoq35cpojcmygP9naB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anish2105/CNN/blob/main/LeNet_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lenet-5 Complete Architecture**"
      ],
      "metadata": {
        "id": "9QT_1WUuWBXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet-5, from the paper Gradient-Based Learning Applied to Document Recognition, is a very efficient convolutional neural network for handwritten character recognition."
      ],
      "metadata": {
        "id": "bF3O7qitWIeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **C1 layer-convolutional layer:**\n",
        "\n",
        "1. **Input picture:** 32 * 32\n",
        "\n",
        "2. **Convolution kernel size:** 5 * 5\n",
        "\n",
        "3. **Convolution kernel types:** 6\n",
        "4. **Output featuremap size:** 28 * 28 : (32-5 + 1) = 28\n",
        "5. **Number of neurons:** 28 28 6\n",
        "\n",
        "6. **Trainable parameters:** (5 5 + 1) 6 (5 * 5 = 25 unit parameters and one bias parameter per filter, a total of 6 filters)\n",
        "7. **Number of connections:** (5 5 + 1) 6 28 28 = 122304"
      ],
      "metadata": {
        "id": "4nTXppOGP1Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**S2 layer-pooling layer (downsampling layer):**\n",
        "1. **Input:** 28 * 28\n",
        "2. **Sampling area:** 2 * 2\n",
        "3. **Sampling method:** 4 inputs are added, multiplied by a trainable parameter, plus a trainable offset. Results via sigmoid\n",
        "4. **Sampling type:** 6\n",
        "5. **Output featureMap size:** 14 * 14 (28/2)\n",
        "6. **Number of neurons:** 14 14 6\n",
        "7. **Trainable parameters:** 2 * 6 (the weight of the sum + the offset)\n",
        "8. **Number of connections:** (2 2 + 1) 6 14 14\n",
        "9. The size of each feature map in S2 is 1/4 of the size of the feature map in C1."
      ],
      "metadata": {
        "id": "qhCF0KgzTIJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**C3 layer-convolutional layer:**\n",
        "1. **Input:** all 6 or several feature map combinations in S2\n",
        "2. **Convolution kernel size:** 5 * 5\n",
        "3. **Convolution kernel type:** 16\n",
        "4. **Output featureMap size:** 10 * 10 (14-5 + 1) = 10\n",
        "5. Each feature map in C3 is connected to all 6 or several feature maps in S2, indicating that the feature map of this layer is a different combination of the feature maps extracted from the previous layer.\n",
        "6. One way is that the first 6 feature maps of C3 take 3 adjacent feature map subsets in S2 as input. The next 6 feature maps take 4 subsets of neighboring feature maps in S2 as input. The next three take the non-adjacent 4 feature map subsets as input. The last one takes all the feature maps in S2 as input.\n",
        "7. The trainable parameters are: 6 (3 5 5 + 1) + 6 (4 5 5 + 1) + 3 (4 5 5 + 1) + 1 (6 5 5 +1) = 1516\n",
        "8. Number of connections: 10 10 1516 = 151600"
      ],
      "metadata": {
        "id": "4lHxjrULbp36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**S4 layer-pooling layer (downsampling layer)**\n",
        "1. **Input:** 10 * 10\n",
        "2. **Sampling area:** 2 * 2\n",
        "3. **Sampling method:** 4 inputs are added, multiplied by a trainable parameter, plus a trainable offset. Results via sigmoid\n",
        "4. **Sampling type:** 16\n",
        "5. **Output featureMap size:** 5 * 5 (10/2)\n",
        "6. **Number of neurons:** 5 5 16 = 400\n",
        "7. **Trainable parameters:** 2 * 16 = 32 (the weight of the sum + the offset)\n",
        "8. **Number of connections:** 16 (2 2 + 1) 5 5 = 2000\n",
        "The size of each feature map in S4 is 1/4 of the size of the feature map in C3"
      ],
      "metadata": {
        "id": "oeOif9GBctGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**C5 layer-convolution layer**\n",
        "1. **Input:** All 16 unit feature maps of the S4 layer (all connected to s4)\n",
        "2. **Convolution kernel size:** 5 * 5\n",
        "3. **Convolution kernel type:** 120\n",
        "4. **Output featureMap size:** 1 * 1 (5-5 + 1)\n",
        "5. **Trainable parameters / connection:** 120 (16 5 * 5 + 1) = 48120"
      ],
      "metadata": {
        "id": "H95-YU8EdnIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D , MaxPooling2D\n",
        "from keras.layers import Dense , Flatten\n",
        "from keras.models import Sequential \n",
        "from tensorflow.keras.utils import to_categorical , plot_model"
      ],
      "metadata": {
        "id": "p8gGPpI2Wb4g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train , y_train ) , (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "ZJkKFB2GkPwN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Data Preprocessing"
      ],
      "metadata": {
        "id": "L172bRX5krUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Peforming reshaping operation\n",
        "x_train = x_train.reshape(x_train.shape[0] , 28,28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0] , 28,28,1)\n",
        "\n",
        "#Normalization\n",
        "x_train =  x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "#One Hot Encoding\n",
        "y_train = to_categorical(y_train , 10)\n",
        "y_test = to_categorical(y_test , 10)"
      ],
      "metadata": {
        "id": "EQGl14BHknSR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeNet Model Architecture**"
      ],
      "metadata": {
        "id": "EESyeeigmi28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6,kernel_size = (5,5),activation = 'tanh',input_shape = (28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(6,kernel_size = (5,5),activation = 'tanh'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120 , activation = 'tanh'))\n",
        "model.add(Dense(84 , activation = 'tanh'))\n",
        "model.add(Dense(10 , activation = 'softmax'))"
      ],
      "metadata": {
        "id": "PMPApUsZmpiK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = keras.metrics.categorical_crossentropy , optimizer = tf.keras.optimizers.Adam() , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "InrMjs2_oBiZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train , y_train , batch_size = 128 , epochs = 20 , verbose = 1 ,validation_data = (x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwcYZwN3oWJG",
        "outputId": "10708cf2-3311-44f7-d8fc-ce32b2f37508"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 7s 9ms/step - loss: 0.3430 - accuracy: 0.9061 - val_loss: 0.1134 - val_accuracy: 0.9658\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1065 - accuracy: 0.9684 - val_loss: 0.0794 - val_accuracy: 0.9751\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0660 - val_accuracy: 0.9795\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0644 - accuracy: 0.9806 - val_loss: 0.0559 - val_accuracy: 0.9819\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.0520 - val_accuracy: 0.9825\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.0453 - val_accuracy: 0.9844\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.0485 - val_accuracy: 0.9833\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0371 - accuracy: 0.9883 - val_loss: 0.0427 - val_accuracy: 0.9847\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.0434 - val_accuracy: 0.9857\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0391 - val_accuracy: 0.9856\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0438 - val_accuracy: 0.9854\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0380 - val_accuracy: 0.9864\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0404 - val_accuracy: 0.9852\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0370 - val_accuracy: 0.9865\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0401 - val_accuracy: 0.9855\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0376 - val_accuracy: 0.9875\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0407 - val_accuracy: 0.9861\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0388 - val_accuracy: 0.9876\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0418 - val_accuracy: 0.9862\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30b0353be0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test , y_test)\n",
        "print('Test Loss: ',score[0])\n",
        "print('Test accuracy: ',score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8E6UiGRos_w",
        "outputId": "1ad6ac18-faea-45a6-9f6a-0ffd08730c1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9862\n",
            "Test Loss:  0.04176131263375282\n",
            "Test accuracy:  0.9861999750137329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_train , y_train)\n",
        "print('Train Loss: ',score[0])\n",
        "print('Train accuracy: ',score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sksls7W9pQ4K",
        "outputId": "d55bd897-819e-42e6-8e1c-965770c425a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0068 - accuracy: 0.9983\n",
            "Train Loss:  0.0068069095723330975\n",
            "Train accuracy:  0.9983166456222534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGdssCl9pxW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}